{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read training images\n",
    "DATADIR = \"./train/\"\n",
    "CATEGORIES = [\"no_yawn\", \"yawn\"]\n",
    "IMG_SIZE = 100\n",
    "\n",
    "training_data = []\n",
    "for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category) # path to cats or dogs dir\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE) # colour is not specific in this use-case\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = [] # features\n",
    "y = [] # labels\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "    \n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # -1 is default, last 1 for grey scale\n",
    "y = np.array(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drowsiness_Detection_Model_0_3_conv_16_nodes_1_dense_1653480043\n",
      "Train on 1158 samples, validate on 290 samples\n",
      "Epoch 1/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 0.7103 - accuracy: 0.4970 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 2/5\n",
      "1158/1158 [==============================] - 2s 2ms/sample - loss: 0.6933 - accuracy: 0.4784 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 3/5\n",
      "1158/1158 [==============================] - 2s 2ms/sample - loss: 0.6933 - accuracy: 0.4870 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 4/5\n",
      "1158/1158 [==============================] - 2s 2ms/sample - loss: 0.6933 - accuracy: 0.4914 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Epoch 5/5\n",
      "1158/1158 [==============================] - 2s 2ms/sample - loss: 0.6932 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.4966\n",
      "Drowsiness_Detection_Model_1_5_conv_16_nodes_1_dense_1653480055\n",
      "Train on 1158 samples, validate on 290 samples\n",
      "Epoch 1/5\n",
      "1158/1158 [==============================] - 3s 3ms/sample - loss: 0.6663 - accuracy: 0.5864 - val_loss: 0.5625 - val_accuracy: 0.6690\n",
      "Epoch 2/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 0.5962 - accuracy: 0.6269 - val_loss: 0.5759 - val_accuracy: 0.6707\n",
      "Epoch 3/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 0.5613 - accuracy: 0.6636 - val_loss: 0.5598 - val_accuracy: 0.6655\n",
      "Epoch 4/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 0.5761 - accuracy: 0.6576 - val_loss: 0.5643 - val_accuracy: 0.6690\n",
      "Epoch 5/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 0.5694 - accuracy: 0.6615 - val_loss: 0.5585 - val_accuracy: 0.6793\n",
      "Drowsiness_Detection_Model_2_3_conv_32_nodes_1_dense_1653480069\n",
      "Train on 1158 samples, validate on 290 samples\n",
      "Epoch 1/5\n",
      "1158/1158 [==============================] - 6s 5ms/sample - loss: 0.8563 - accuracy: 0.6209 - val_loss: 0.5834 - val_accuracy: 0.6724\n",
      "Epoch 2/5\n",
      "1158/1158 [==============================] - 6s 5ms/sample - loss: 0.5832 - accuracy: 0.6598 - val_loss: 0.6088 - val_accuracy: 0.5586\n",
      "Epoch 3/5\n",
      "1158/1158 [==============================] - 6s 5ms/sample - loss: 0.5746 - accuracy: 0.6537 - val_loss: 0.5885 - val_accuracy: 0.6569\n",
      "Epoch 4/5\n",
      "1158/1158 [==============================] - 7s 6ms/sample - loss: 0.5821 - accuracy: 0.6572 - val_loss: 0.5475 - val_accuracy: 0.6707\n",
      "Epoch 5/5\n",
      "1158/1158 [==============================] - 7s 6ms/sample - loss: 0.5608 - accuracy: 0.6844 - val_loss: 0.5226 - val_accuracy: 0.7172\n",
      "Drowsiness_Detection_Model_3_5_conv_32_nodes_1_dense_1653480100\n",
      "Train on 1158 samples, validate on 290 samples\n",
      "Epoch 1/5\n",
      "1158/1158 [==============================] - 5s 4ms/sample - loss: 0.6549 - accuracy: 0.6244 - val_loss: 0.5490 - val_accuracy: 0.7069\n",
      "Epoch 2/5\n",
      "1158/1158 [==============================] - 4s 4ms/sample - loss: 0.5863 - accuracy: 0.6654 - val_loss: 0.5417 - val_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "1158/1158 [==============================] - 4s 4ms/sample - loss: 0.5555 - accuracy: 0.6852 - val_loss: 0.5353 - val_accuracy: 0.7052\n",
      "Epoch 4/5\n",
      "1158/1158 [==============================] - 4s 4ms/sample - loss: 0.5243 - accuracy: 0.7155 - val_loss: 0.5221 - val_accuracy: 0.7207\n",
      "Epoch 5/5\n",
      "1158/1158 [==============================] - 4s 4ms/sample - loss: 0.5007 - accuracy: 0.7323 - val_loss: 0.5016 - val_accuracy: 0.7293\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "num_classes = 4\n",
    "\n",
    "# compare different architectures\n",
    "dense_layers = [1]\n",
    "layer_sizes = [16, 32]\n",
    "conv_layers = [3, 5]\n",
    "\n",
    "model = [Sequential() for i in range(len(dense_layers)*len(layer_sizes)*len(conv_layers))]\n",
    "idx = 0\n",
    "\n",
    "for dense_layer in dense_layers: \n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            # analyse model\n",
    "            NAME = 'Drowsiness_Detection_Model_{}_{}_conv_{}_nodes_{}_dense_{}'.format(idx, conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            # input layer\n",
    "            model[idx].add(Conv2D(layer_size, (3,3), input_shape = X.shape[1:]))\n",
    "            model[idx].add(Activation('relu'))\n",
    "            model[idx].add(MaxPooling2D(pool_size = (2,2))) \n",
    "            \n",
    "            # hidden convulational layers (='filters')\n",
    "            for l in range(conv_layer-1):\n",
    "                model[idx].add(Conv2D(layer_size, (3,3)))\n",
    "                model[idx].add(Activation('relu'))\n",
    "                model[idx].add(MaxPooling2D(pool_size = (2,2)))\n",
    "            \n",
    "            # hidden dense (=fully connected) layers\n",
    "            model[idx].add(Flatten())\n",
    "            for l in range(dense_layer):\n",
    "                model[idx].add(Dense(layer_size))\n",
    "                model[idx].add(Activation('relu'))\n",
    "\n",
    "            # output layer\n",
    "            model[idx].add(Dense(len(CATEGORIES)))\n",
    "            model[idx].add(Activation('sigmoid'))\n",
    "\n",
    "            model[idx].compile(loss='binary_crossentropy',\n",
    "                         optimizer='adam',\n",
    "                         metrics=['accuracy'])\n",
    "\n",
    "            model[idx].fit(X, y, batch_size=4, epochs=5, validation_split = 0.2) # appropriate batch size depends on size of data set\n",
    "            idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n",
      "yawning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-6b51efd3460a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'yawning'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m     \u001B[1;32mif\u001B[0m \u001B[0mcv2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwaitKey\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m&\u001B[0m \u001B[1;36m0xFF\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m27\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m         \u001B[1;32mbreak\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    grayFrame = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    grayFrame = cv2.resize(grayFrame, (IMG_SIZE, IMG_SIZE))\n",
    "    cv2.imshow('Video Stream', grayFrame)\n",
    "    grayFrame = np.array(grayFrame).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # -1 is default, last 1 for grey scale\n",
    "    pred = model[2].predict(grayFrame)\n",
    "    \n",
    "    if(pred[0,1] > 0.8):\n",
    "        print('yawning')\n",
    "    \n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}